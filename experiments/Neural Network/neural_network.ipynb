{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Networks\n",
    "\n",
    "#### This notebook covers our team's Neural Network Implementation.\n",
    "\n",
    "We have tried 5 different architectures-hyperparameter combinations in total. We train on the 'train_clean.csv', which the train dataset obtained after processing all the EDA steps mentioned in the 'EDA.ipynb'.\n",
    "At the end of the notebook, there is a comparison of the performances of the five models and test set prediction by using the best neural network model.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b6791024cb8c49"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T06:13:45.418116900Z",
     "start_time": "2023-11-07T06:13:45.404149700Z"
    }
   },
   "id": "1b0cf96b37b1623d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_train =pd.read_csv('../../datasets/final/train_clean.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T06:13:46.697120500Z",
     "start_time": "2023-11-07T06:13:46.150066Z"
    }
   },
   "id": "6ef998edac1be716"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   rent_approval_date  flat_type  floor_area_sqm  lease_commence_date  \\\n0            0.266740       0.25        0.182320             0.320755   \n1            0.532382       0.50        0.320442             0.226415   \n2            0.700329       0.25        0.182320             0.094340   \n3            0.232711       1.00        0.635359             0.509434   \n4            0.734358       0.25        0.187845             0.113208   \n\n   latitude   longitude  monthly_rent  distance_to_nearest_existing_mrt  \\\n0  1.344518  103.738630          1600                          0.271900   \n1  1.330186  103.938717          2250                          0.353866   \n2  1.332242  103.845643          1900                          0.074831   \n3  1.370239  103.962894          2850                          0.619229   \n4  1.320502  103.863341          2100                          0.062221   \n\n   distance_to_nearest_planned_mrt  distance_to_nearest_school  ...  \\\n0                         0.067848                    0.143355  ...   \n1                         0.092239                    0.277286  ...   \n2                         0.391439                    0.187977  ...   \n3                         0.050944                    0.256304  ...   \n4                         0.297298                    0.112373  ...   \n\n   town_pasir ris  town_punggol  town_queenstown  town_sembawang  \\\n0           False         False            False           False   \n1           False         False            False           False   \n2           False         False            False           False   \n3            True         False            False           False   \n4           False         False            False           False   \n\n   town_sengkang  town_serangoon  town_tampines  town_toa payoh  \\\n0          False           False          False           False   \n1          False           False          False           False   \n2          False           False          False            True   \n3          False           False          False           False   \n4          False           False          False           False   \n\n   town_woodlands  town_yishun  \n0           False        False  \n1           False        False  \n2           False        False  \n3           False        False  \n4           False        False  \n\n[5 rows x 47 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rent_approval_date</th>\n      <th>flat_type</th>\n      <th>floor_area_sqm</th>\n      <th>lease_commence_date</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>monthly_rent</th>\n      <th>distance_to_nearest_existing_mrt</th>\n      <th>distance_to_nearest_planned_mrt</th>\n      <th>distance_to_nearest_school</th>\n      <th>...</th>\n      <th>town_pasir ris</th>\n      <th>town_punggol</th>\n      <th>town_queenstown</th>\n      <th>town_sembawang</th>\n      <th>town_sengkang</th>\n      <th>town_serangoon</th>\n      <th>town_tampines</th>\n      <th>town_toa payoh</th>\n      <th>town_woodlands</th>\n      <th>town_yishun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.266740</td>\n      <td>0.25</td>\n      <td>0.182320</td>\n      <td>0.320755</td>\n      <td>1.344518</td>\n      <td>103.738630</td>\n      <td>1600</td>\n      <td>0.271900</td>\n      <td>0.067848</td>\n      <td>0.143355</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.532382</td>\n      <td>0.50</td>\n      <td>0.320442</td>\n      <td>0.226415</td>\n      <td>1.330186</td>\n      <td>103.938717</td>\n      <td>2250</td>\n      <td>0.353866</td>\n      <td>0.092239</td>\n      <td>0.277286</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.700329</td>\n      <td>0.25</td>\n      <td>0.182320</td>\n      <td>0.094340</td>\n      <td>1.332242</td>\n      <td>103.845643</td>\n      <td>1900</td>\n      <td>0.074831</td>\n      <td>0.391439</td>\n      <td>0.187977</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.232711</td>\n      <td>1.00</td>\n      <td>0.635359</td>\n      <td>0.509434</td>\n      <td>1.370239</td>\n      <td>103.962894</td>\n      <td>2850</td>\n      <td>0.619229</td>\n      <td>0.050944</td>\n      <td>0.256304</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.734358</td>\n      <td>0.25</td>\n      <td>0.187845</td>\n      <td>0.113208</td>\n      <td>1.320502</td>\n      <td>103.863341</td>\n      <td>2100</td>\n      <td>0.062221</td>\n      <td>0.297298</td>\n      <td>0.112373</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 47 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T06:13:46.705609200Z",
     "start_time": "2023-11-07T06:13:46.667964300Z"
    }
   },
   "id": "55fd742fab05bae9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preparing and Splitting the dataset into train and val"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a195d415c8494f"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_train = df_train.drop('monthly_rent', axis=1)\n",
    "y_train = df_train['monthly_rent']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T06:13:48.710482600Z",
     "start_time": "2023-11-07T06:13:48.687163500Z"
    }
   },
   "id": "717b97be6cf6f7a8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T06:13:50.044875500Z",
     "start_time": "2023-11-07T06:13:50.027746100Z"
    }
   },
   "id": "62681666d70c18ec"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T06:13:51.085231500Z",
     "start_time": "2023-11-07T06:13:51.031841600Z"
    }
   },
   "id": "8096bd181860f7c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model-1: \n",
    "This is a simple architecture in which there is a mid-section spike from 64 neurons to 128 neurons. The input dimension is 46 which is the number of features in 'train_clean'. The model is trained for 100 epochs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fee5414813590f2d"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, RMSE: 785.8766\n",
      "Epoch 2/100, RMSE: 522.9919\n",
      "Epoch 3/100, RMSE: 514.7362\n",
      "Epoch 4/100, RMSE: 512.5783\n",
      "Epoch 5/100, RMSE: 511.5088\n",
      "Epoch 6/100, RMSE: 510.8309\n",
      "Epoch 7/100, RMSE: 510.3884\n",
      "Epoch 8/100, RMSE: 510.0048\n",
      "Epoch 9/100, RMSE: 509.6690\n",
      "Epoch 10/100, RMSE: 509.4381\n",
      "Epoch 11/100, RMSE: 509.1405\n",
      "Epoch 12/100, RMSE: 508.9160\n",
      "Epoch 13/100, RMSE: 508.7526\n",
      "Epoch 14/100, RMSE: 508.4435\n",
      "Epoch 15/100, RMSE: 508.2274\n",
      "Epoch 16/100, RMSE: 507.9902\n",
      "Epoch 17/100, RMSE: 507.8317\n",
      "Epoch 18/100, RMSE: 507.5518\n",
      "Epoch 19/100, RMSE: 507.2876\n",
      "Epoch 20/100, RMSE: 507.0728\n",
      "Epoch 21/100, RMSE: 506.9119\n",
      "Epoch 22/100, RMSE: 506.6514\n",
      "Epoch 23/100, RMSE: 506.4364\n",
      "Epoch 24/100, RMSE: 506.2107\n",
      "Epoch 25/100, RMSE: 505.9876\n",
      "Epoch 26/100, RMSE: 505.8299\n",
      "Epoch 27/100, RMSE: 505.5454\n",
      "Epoch 28/100, RMSE: 505.4079\n",
      "Epoch 29/100, RMSE: 505.2676\n",
      "Epoch 30/100, RMSE: 504.9849\n",
      "Epoch 31/100, RMSE: 504.8386\n",
      "Epoch 32/100, RMSE: 504.6833\n",
      "Epoch 33/100, RMSE: 504.6223\n",
      "Epoch 34/100, RMSE: 504.4175\n",
      "Epoch 35/100, RMSE: 504.3293\n",
      "Epoch 36/100, RMSE: 504.2214\n",
      "Epoch 37/100, RMSE: 504.0501\n",
      "Epoch 38/100, RMSE: 504.1159\n",
      "Epoch 39/100, RMSE: 503.8813\n",
      "Epoch 40/100, RMSE: 503.8110\n",
      "Epoch 41/100, RMSE: 503.7600\n",
      "Epoch 42/100, RMSE: 503.5255\n",
      "Epoch 43/100, RMSE: 503.4843\n",
      "Epoch 44/100, RMSE: 503.3141\n",
      "Epoch 45/100, RMSE: 503.2499\n",
      "Epoch 46/100, RMSE: 503.0892\n",
      "Epoch 47/100, RMSE: 502.9038\n",
      "Epoch 48/100, RMSE: 502.9138\n",
      "Epoch 49/100, RMSE: 502.8509\n",
      "Epoch 50/100, RMSE: 502.7095\n",
      "Epoch 51/100, RMSE: 502.6172\n",
      "Epoch 52/100, RMSE: 502.4995\n",
      "Epoch 53/100, RMSE: 502.4815\n",
      "Epoch 54/100, RMSE: 502.3194\n",
      "Epoch 55/100, RMSE: 502.2031\n",
      "Epoch 56/100, RMSE: 502.1114\n",
      "Epoch 57/100, RMSE: 502.0897\n",
      "Epoch 58/100, RMSE: 502.0045\n",
      "Epoch 59/100, RMSE: 501.9739\n",
      "Epoch 60/100, RMSE: 501.8866\n",
      "Epoch 61/100, RMSE: 501.8355\n",
      "Epoch 62/100, RMSE: 501.7085\n",
      "Epoch 63/100, RMSE: 501.4208\n",
      "Epoch 64/100, RMSE: 501.1330\n",
      "Epoch 65/100, RMSE: 500.6612\n",
      "Epoch 66/100, RMSE: 499.9849\n",
      "Epoch 67/100, RMSE: 499.4873\n",
      "Epoch 68/100, RMSE: 498.8158\n",
      "Epoch 69/100, RMSE: 498.3072\n",
      "Epoch 70/100, RMSE: 498.0624\n",
      "Epoch 71/100, RMSE: 497.8435\n",
      "Epoch 72/100, RMSE: 497.5908\n",
      "Epoch 73/100, RMSE: 497.4012\n",
      "Epoch 74/100, RMSE: 497.1412\n",
      "Epoch 75/100, RMSE: 496.9906\n",
      "Epoch 76/100, RMSE: 496.9157\n",
      "Epoch 77/100, RMSE: 496.6879\n",
      "Epoch 78/100, RMSE: 496.5973\n",
      "Epoch 79/100, RMSE: 496.4064\n",
      "Epoch 80/100, RMSE: 496.2273\n",
      "Epoch 81/100, RMSE: 496.1265\n",
      "Epoch 82/100, RMSE: 496.1185\n",
      "Epoch 83/100, RMSE: 495.9361\n",
      "Epoch 84/100, RMSE: 495.8912\n",
      "Epoch 85/100, RMSE: 495.7340\n",
      "Epoch 86/100, RMSE: 495.6671\n",
      "Epoch 87/100, RMSE: 495.5971\n",
      "Epoch 88/100, RMSE: 495.5032\n",
      "Epoch 89/100, RMSE: 495.2384\n",
      "Epoch 90/100, RMSE: 495.2484\n",
      "Epoch 91/100, RMSE: 495.1959\n",
      "Epoch 92/100, RMSE: 495.1268\n",
      "Epoch 93/100, RMSE: 494.8714\n",
      "Epoch 94/100, RMSE: 494.8221\n",
      "Epoch 95/100, RMSE: 494.6073\n",
      "Epoch 96/100, RMSE: 494.5672\n",
      "Epoch 97/100, RMSE: 494.4757\n",
      "Epoch 98/100, RMSE: 494.3747\n",
      "Epoch 99/100, RMSE: 494.3197\n",
      "Epoch 100/100, RMSE: 494.2079\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Input(shape=(46,)))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "total_batches = len(X_train) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_losses = []\n",
    "\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_X = X_train[i:i + batch_size]\n",
    "        batch_y = y_train[i:i + batch_size]\n",
    "        loss = model.train_on_batch(batch_X, batch_y)\n",
    "        epoch_losses.append(loss)\n",
    "\n",
    "    \n",
    "    rmse = np.sqrt(np.mean(epoch_losses))\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, RMSE: {rmse:.4f}')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T04:44:18.163776800Z",
     "start_time": "2023-11-06T03:57:37.143651300Z"
    }
   },
   "id": "f3cdc71d4a3e23b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"nn_regression_model_1.h5\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "374a39013d52fb89"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val)\n",
    "\n",
    "predictions = predictions.reshape(9517,)\n",
    "\n",
    "rmse_val = np.sqrt(np.mean((predictions - y_val) ** 2))\n",
    "print(f'RMSE on Validation Set: {rmse_val:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:43:37.995589600Z",
     "start_time": "2023-11-05T10:43:37.976501400Z"
    }
   },
   "id": "3b26b47f08c3fba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model-2: \n",
    "This is a deeper model in which the architecture is increased in powers of 2 up until 512 and then brought back down linearly. A Learning Rate Scheduler is utilised here. The model is trained for 100 epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64f9dcde857848c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "# Root Mean Squared Error (RMSE) custom loss function\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_factor = 0.96\n",
    "    decay_steps = 3\n",
    "    lr = initial_learning_rate * (decay_factor ** (epoch // decay_steps))\n",
    "    return lr\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(46,)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(8, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=rmse)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[lr_callback])\n",
    "\n",
    "model.save(\"nn_regression_model_2.h5\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82236052962f8c75"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298/298 [==============================] - 1s 2ms/step\n",
      "RMSE on Validation Set: 492.2489\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the validation set\n",
    "predictions = model.predict(X_val)\n",
    "a,b = predictions.shape\n",
    "predictions = predictions.reshape(a,)\n",
    "\n",
    "# Calculating RMSE on the validation set\n",
    "rmse_val = np.sqrt(np.mean((predictions - y_val) ** 2))\n",
    "print(f'RMSE on Validation Set: {rmse_val:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T12:08:39.980332500Z",
     "start_time": "2023-11-05T12:08:39.073729100Z"
    }
   },
   "id": "b162eabceae606db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model-3: \n",
    "This model is deeper than Model-2. The number of neurons are increased up until 1024 and then brought back down. Learning Rate scheduler is employed here too with a decay factor of 0.96. 'batch_size' of 64 is used and trained for 100 epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d57d1d10cfa90225"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_factor = 0.96\n",
    "    decay_steps = 3\n",
    "    lr = initial_learning_rate * (decay_factor ** (epoch // decay_steps))\n",
    "    return lr\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(46,)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(8, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(4, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(2, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=rmse)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[lr_callback])\n",
    "\n",
    "\n",
    "model.save(\"nn_regression_model_3.h5\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "861ddebc1883ca26"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298/298 [==============================] - 2s 5ms/step\n",
      "RMSE on Validation Set: 493.9776\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the validation set\n",
    "predictions = model.predict(X_val)\n",
    "a,b = predictions.shape\n",
    "predictions = predictions.reshape(a,)\n",
    "\n",
    "# Calculating RMSE on the validation set\n",
    "rmse_val = np.sqrt(np.mean((predictions - y_val) ** 2))\n",
    "print(f'RMSE on Validation Set: {rmse_val:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:26:06.267520Z",
     "start_time": "2023-11-05T13:26:04.398788300Z"
    }
   },
   "id": "87a8f66bdc9b84ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model-4: \n",
    "Increasing the number of neurons did not yield in betetr results. Hence we tried to trim down the model and limit the number of neurons in the deeper layers to 256. 'batch_size' of 32 is used and the model is trained for 200 epochs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "258d61cd8d64cd2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_factor = 0.96\n",
    "    decay_steps = 3\n",
    "    lr = initial_learning_rate * (decay_factor ** (epoch // decay_steps))\n",
    "    return lr\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(46,)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(8, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(4, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(2, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=rmse)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[lr_callback])\n",
    "\n",
    "model.save(\"nn_regression_model_4.h5\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f58a4d8375534709"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298/298 [==============================] - 0s 1ms/step\n",
      "RMSE on Validation Set: 491.8362\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the validation set\n",
    "predictions = model.predict(X_val)\n",
    "a,b = predictions.shape\n",
    "predictions = predictions.reshape(a,)\n",
    "\n",
    "# Calculating RMSE on the validation set\n",
    "rmse_val = np.sqrt(np.mean((predictions - y_val) ** 2))\n",
    "print(f'RMSE on Validation Set: {rmse_val:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:58:41.279464Z",
     "start_time": "2023-11-05T13:58:40.645007400Z"
    }
   },
   "id": "d1cd9a033e3d8652"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "263aa64777100583"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model-5: \n",
    "This is an even more trimmed down model, more similar to Model-1. The model is trained for 200 epochs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a72f83758dc4b55"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 499486.4062 - root_mean_squared_error: 706.7433 - val_loss: 261857.4062 - val_root_mean_squared_error: 511.7196 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 268098.9062 - root_mean_squared_error: 517.7823 - val_loss: 248191.7344 - val_root_mean_squared_error: 498.1881 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1487/1487 [==============================] - 5s 3ms/step - loss: 264903.1562 - root_mean_squared_error: 514.6871 - val_loss: 246859.4531 - val_root_mean_squared_error: 496.8490 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 263542.0938 - root_mean_squared_error: 513.3631 - val_loss: 249768.6875 - val_root_mean_squared_error: 499.7682 - lr: 9.6000e-04\n",
      "Epoch 5/200\n",
      "1487/1487 [==============================] - 11s 8ms/step - loss: 263331.0312 - root_mean_squared_error: 513.1575 - val_loss: 254365.7812 - val_root_mean_squared_error: 504.3465 - lr: 9.6000e-04\n",
      "Epoch 6/200\n",
      "1487/1487 [==============================] - 11s 8ms/step - loss: 263032.3438 - root_mean_squared_error: 512.8663 - val_loss: 249468.6875 - val_root_mean_squared_error: 499.4679 - lr: 9.6000e-04\n",
      "Epoch 7/200\n",
      "1487/1487 [==============================] - 13s 9ms/step - loss: 260655.7031 - root_mean_squared_error: 510.5441 - val_loss: 244817.8906 - val_root_mean_squared_error: 494.7903 - lr: 9.2160e-04\n",
      "Epoch 8/200\n",
      "1487/1487 [==============================] - 17s 11ms/step - loss: 261207.5000 - root_mean_squared_error: 511.0842 - val_loss: 246484.5312 - val_root_mean_squared_error: 496.4715 - lr: 9.2160e-04\n",
      "Epoch 9/200\n",
      "1487/1487 [==============================] - 16s 11ms/step - loss: 259069.3125 - root_mean_squared_error: 508.9881 - val_loss: 247047.1250 - val_root_mean_squared_error: 497.0378 - lr: 9.2160e-04\n",
      "Epoch 10/200\n",
      "1487/1487 [==============================] - 21s 14ms/step - loss: 259140.2500 - root_mean_squared_error: 509.0577 - val_loss: 245001.5156 - val_root_mean_squared_error: 494.9757 - lr: 8.8474e-04\n",
      "Epoch 11/200\n",
      "1487/1487 [==============================] - 23s 15ms/step - loss: 259255.8281 - root_mean_squared_error: 509.1711 - val_loss: 245864.3281 - val_root_mean_squared_error: 495.8467 - lr: 8.8474e-04\n",
      "Epoch 12/200\n",
      "1487/1487 [==============================] - 20s 13ms/step - loss: 259153.4219 - root_mean_squared_error: 509.0707 - val_loss: 244588.9531 - val_root_mean_squared_error: 494.5587 - lr: 8.8474e-04\n",
      "Epoch 13/200\n",
      "1487/1487 [==============================] - 22s 15ms/step - loss: 259164.8906 - root_mean_squared_error: 509.0818 - val_loss: 254500.9688 - val_root_mean_squared_error: 504.4803 - lr: 8.4935e-04\n",
      "Epoch 14/200\n",
      "1487/1487 [==============================] - 24s 16ms/step - loss: 257391.8594 - root_mean_squared_error: 507.3375 - val_loss: 243112.3906 - val_root_mean_squared_error: 493.0636 - lr: 8.4935e-04\n",
      "Epoch 15/200\n",
      "1487/1487 [==============================] - 22s 15ms/step - loss: 256835.3438 - root_mean_squared_error: 506.7886 - val_loss: 249519.7344 - val_root_mean_squared_error: 499.5188 - lr: 8.4935e-04\n",
      "Epoch 16/200\n",
      "1487/1487 [==============================] - 25s 17ms/step - loss: 256080.6250 - root_mean_squared_error: 506.0435 - val_loss: 243869.4531 - val_root_mean_squared_error: 493.8308 - lr: 8.1537e-04\n",
      "Epoch 17/200\n",
      "1487/1487 [==============================] - 29s 19ms/step - loss: 255694.8906 - root_mean_squared_error: 505.6622 - val_loss: 256623.9688 - val_root_mean_squared_error: 506.5800 - lr: 8.1537e-04\n",
      "Epoch 18/200\n",
      "1487/1487 [==============================] - 27s 18ms/step - loss: 257321.4688 - root_mean_squared_error: 507.2680 - val_loss: 244625.0625 - val_root_mean_squared_error: 494.5952 - lr: 8.1537e-04\n",
      "Epoch 19/200\n",
      "1487/1487 [==============================] - 22s 15ms/step - loss: 255329.2500 - root_mean_squared_error: 505.3005 - val_loss: 241785.9688 - val_root_mean_squared_error: 491.7167 - lr: 7.8276e-04\n",
      "Epoch 20/200\n",
      "1487/1487 [==============================] - 11s 7ms/step - loss: 254431.0625 - root_mean_squared_error: 504.4112 - val_loss: 245189.0000 - val_root_mean_squared_error: 495.1653 - lr: 7.8276e-04\n",
      "Epoch 21/200\n",
      "1487/1487 [==============================] - 4s 3ms/step - loss: 254080.2812 - root_mean_squared_error: 504.0632 - val_loss: 241494.7656 - val_root_mean_squared_error: 491.4206 - lr: 7.8276e-04\n",
      "Epoch 22/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 253556.4688 - root_mean_squared_error: 503.5433 - val_loss: 242024.9688 - val_root_mean_squared_error: 491.9598 - lr: 7.5145e-04\n",
      "Epoch 23/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 252554.3750 - root_mean_squared_error: 502.5472 - val_loss: 239986.2656 - val_root_mean_squared_error: 489.8834 - lr: 7.5145e-04\n",
      "Epoch 24/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 252665.8438 - root_mean_squared_error: 502.6581 - val_loss: 239584.6719 - val_root_mean_squared_error: 489.4733 - lr: 7.5145e-04\n",
      "Epoch 25/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 251341.2656 - root_mean_squared_error: 501.3389 - val_loss: 239632.5312 - val_root_mean_squared_error: 489.5222 - lr: 7.2139e-04\n",
      "Epoch 26/200\n",
      "1487/1487 [==============================] - 4s 3ms/step - loss: 251695.0781 - root_mean_squared_error: 501.6916 - val_loss: 240964.4375 - val_root_mean_squared_error: 490.8807 - lr: 7.2139e-04\n",
      "Epoch 27/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 250050.2656 - root_mean_squared_error: 500.0499 - val_loss: 239655.6406 - val_root_mean_squared_error: 489.5456 - lr: 7.2139e-04\n",
      "Epoch 28/200\n",
      "1487/1487 [==============================] - 4s 3ms/step - loss: 250195.8438 - root_mean_squared_error: 500.1952 - val_loss: 245374.8594 - val_root_mean_squared_error: 495.3527 - lr: 6.9253e-04\n",
      "Epoch 29/200\n",
      "1487/1487 [==============================] - 4s 3ms/step - loss: 248818.1562 - root_mean_squared_error: 498.8161 - val_loss: 245023.3750 - val_root_mean_squared_error: 494.9977 - lr: 6.9253e-04\n",
      "Epoch 30/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 249212.0625 - root_mean_squared_error: 499.2109 - val_loss: 240390.8906 - val_root_mean_squared_error: 490.2960 - lr: 6.9253e-04\n",
      "Epoch 31/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 249028.0625 - root_mean_squared_error: 499.0264 - val_loss: 256758.2969 - val_root_mean_squared_error: 506.7126 - lr: 6.6483e-04\n",
      "Epoch 32/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 248709.3438 - root_mean_squared_error: 498.7071 - val_loss: 246152.5000 - val_root_mean_squared_error: 496.1370 - lr: 6.6483e-04\n",
      "Epoch 33/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 248399.5469 - root_mean_squared_error: 498.3962 - val_loss: 237149.7812 - val_root_mean_squared_error: 486.9796 - lr: 6.6483e-04\n",
      "Epoch 34/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 247922.0469 - root_mean_squared_error: 497.9173 - val_loss: 239903.1250 - val_root_mean_squared_error: 489.7983 - lr: 6.3824e-04\n",
      "Epoch 35/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 247370.4062 - root_mean_squared_error: 497.3628 - val_loss: 241107.9531 - val_root_mean_squared_error: 491.0268 - lr: 6.3824e-04\n",
      "Epoch 36/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 248118.4219 - root_mean_squared_error: 498.1143 - val_loss: 245723.8750 - val_root_mean_squared_error: 495.7048 - lr: 6.3824e-04\n",
      "Epoch 37/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 246943.2188 - root_mean_squared_error: 496.9332 - val_loss: 242346.2812 - val_root_mean_squared_error: 492.2861 - lr: 6.1271e-04\n",
      "Epoch 38/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 248058.2656 - root_mean_squared_error: 498.0539 - val_loss: 252818.9375 - val_root_mean_squared_error: 502.8105 - lr: 6.1271e-04\n",
      "Epoch 39/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 247385.2969 - root_mean_squared_error: 497.3778 - val_loss: 237587.0000 - val_root_mean_squared_error: 487.4284 - lr: 6.1271e-04\n",
      "Epoch 40/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 246682.0781 - root_mean_squared_error: 496.6703 - val_loss: 237413.5156 - val_root_mean_squared_error: 487.2503 - lr: 5.8820e-04\n",
      "Epoch 41/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 247598.3438 - root_mean_squared_error: 497.5919 - val_loss: 236672.2969 - val_root_mean_squared_error: 486.4892 - lr: 5.8820e-04\n",
      "Epoch 42/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 246784.4688 - root_mean_squared_error: 496.7733 - val_loss: 243408.7500 - val_root_mean_squared_error: 493.3640 - lr: 5.8820e-04\n",
      "Epoch 43/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 246011.4688 - root_mean_squared_error: 495.9947 - val_loss: 241384.0000 - val_root_mean_squared_error: 491.3079 - lr: 5.6467e-04\n",
      "Epoch 44/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 246831.9062 - root_mean_squared_error: 496.8212 - val_loss: 237016.5938 - val_root_mean_squared_error: 486.8427 - lr: 5.6467e-04\n",
      "Epoch 45/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 246089.0625 - root_mean_squared_error: 496.0729 - val_loss: 236887.0312 - val_root_mean_squared_error: 486.7098 - lr: 5.6467e-04\n",
      "Epoch 46/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 246105.5000 - root_mean_squared_error: 496.0894 - val_loss: 235855.0000 - val_root_mean_squared_error: 485.6483 - lr: 5.4209e-04\n",
      "Epoch 47/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 246015.0469 - root_mean_squared_error: 495.9984 - val_loss: 240121.0781 - val_root_mean_squared_error: 490.0208 - lr: 5.4209e-04\n",
      "Epoch 48/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 245486.8594 - root_mean_squared_error: 495.4656 - val_loss: 235876.9688 - val_root_mean_squared_error: 485.6709 - lr: 5.4209e-04\n",
      "Epoch 49/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 245546.4375 - root_mean_squared_error: 495.5256 - val_loss: 235625.7656 - val_root_mean_squared_error: 485.4123 - lr: 5.2040e-04\n",
      "Epoch 50/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 244696.2031 - root_mean_squared_error: 494.6670 - val_loss: 236761.1562 - val_root_mean_squared_error: 486.5804 - lr: 5.2040e-04\n",
      "Epoch 51/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 245326.6719 - root_mean_squared_error: 495.3038 - val_loss: 243764.1875 - val_root_mean_squared_error: 493.7241 - lr: 5.2040e-04\n",
      "Epoch 52/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 244951.9219 - root_mean_squared_error: 494.9256 - val_loss: 237653.0469 - val_root_mean_squared_error: 487.4961 - lr: 4.9959e-04\n",
      "Epoch 53/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 245310.1250 - root_mean_squared_error: 495.2872 - val_loss: 235982.4844 - val_root_mean_squared_error: 485.7795 - lr: 4.9959e-04\n",
      "Epoch 54/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 244802.2656 - root_mean_squared_error: 494.7743 - val_loss: 236586.2656 - val_root_mean_squared_error: 486.4006 - lr: 4.9959e-04\n",
      "Epoch 55/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 244529.4688 - root_mean_squared_error: 494.4983 - val_loss: 235694.4844 - val_root_mean_squared_error: 485.4828 - lr: 4.7960e-04\n",
      "Epoch 56/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 244310.5625 - root_mean_squared_error: 494.2771 - val_loss: 235579.4375 - val_root_mean_squared_error: 485.3645 - lr: 4.7960e-04\n",
      "Epoch 57/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 244223.5625 - root_mean_squared_error: 494.1892 - val_loss: 237972.2344 - val_root_mean_squared_error: 487.8232 - lr: 4.7960e-04\n",
      "Epoch 58/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 243918.7812 - root_mean_squared_error: 493.8807 - val_loss: 235807.7344 - val_root_mean_squared_error: 485.5997 - lr: 4.6042e-04\n",
      "Epoch 59/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 244365.6406 - root_mean_squared_error: 494.3329 - val_loss: 256983.3906 - val_root_mean_squared_error: 506.9346 - lr: 4.6042e-04\n",
      "Epoch 60/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 243941.4844 - root_mean_squared_error: 493.9036 - val_loss: 238225.0000 - val_root_mean_squared_error: 488.0823 - lr: 4.6042e-04\n",
      "Epoch 61/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 244224.8281 - root_mean_squared_error: 494.1903 - val_loss: 235630.1094 - val_root_mean_squared_error: 485.4167 - lr: 4.4200e-04\n",
      "Epoch 62/200\n",
      "1487/1487 [==============================] - 3s 2ms/step - loss: 243625.6719 - root_mean_squared_error: 493.5839 - val_loss: 239014.9688 - val_root_mean_squared_error: 488.8907 - lr: 4.4200e-04\n",
      "Epoch 63/200\n",
      "1487/1487 [==============================] - 4s 2ms/step - loss: 243591.6250 - root_mean_squared_error: 493.5495 - val_loss: 235085.0469 - val_root_mean_squared_error: 484.8551 - lr: 4.4200e-04\n",
      "Epoch 64/200\n",
      "1487/1487 [==============================] - 7s 5ms/step - loss: 243093.0469 - root_mean_squared_error: 493.0439 - val_loss: 245833.7656 - val_root_mean_squared_error: 495.8156 - lr: 4.2432e-04\n",
      "Epoch 65/200\n",
      "1487/1487 [==============================] - 11s 8ms/step - loss: 243141.7500 - root_mean_squared_error: 493.0935 - val_loss: 235254.0625 - val_root_mean_squared_error: 485.0293 - lr: 4.2432e-04\n",
      "Epoch 66/200\n",
      "1487/1487 [==============================] - 11s 7ms/step - loss: 243310.1094 - root_mean_squared_error: 493.2640 - val_loss: 238399.3594 - val_root_mean_squared_error: 488.2608 - lr: 4.2432e-04\n",
      "Epoch 67/200\n",
      "1487/1487 [==============================] - 15s 10ms/step - loss: 243417.8438 - root_mean_squared_error: 493.3733 - val_loss: 237295.0000 - val_root_mean_squared_error: 487.1288 - lr: 4.0735e-04\n",
      "Epoch 68/200\n",
      "1487/1487 [==============================] - 14s 10ms/step - loss: 243594.6094 - root_mean_squared_error: 493.5523 - val_loss: 240557.0781 - val_root_mean_squared_error: 490.4655 - lr: 4.0735e-04\n",
      "Epoch 69/200\n",
      "1487/1487 [==============================] - 14s 9ms/step - loss: 243320.6875 - root_mean_squared_error: 493.2746 - val_loss: 240645.8594 - val_root_mean_squared_error: 490.5559 - lr: 4.0735e-04\n",
      "Epoch 70/200\n",
      "1487/1487 [==============================] - 16s 11ms/step - loss: 243590.8281 - root_mean_squared_error: 493.5485 - val_loss: 234720.6875 - val_root_mean_squared_error: 484.4792 - lr: 3.9106e-04\n",
      "Epoch 71/200\n",
      "1487/1487 [==============================] - 19s 13ms/step - loss: 243120.0156 - root_mean_squared_error: 493.0713 - val_loss: 235095.2031 - val_root_mean_squared_error: 484.8654 - lr: 3.9106e-04\n",
      "Epoch 72/200\n",
      "1487/1487 [==============================] - 21s 14ms/step - loss: 242861.7344 - root_mean_squared_error: 492.8093 - val_loss: 236570.0156 - val_root_mean_squared_error: 486.3839 - lr: 3.9106e-04\n",
      "Epoch 73/200\n",
      "1487/1487 [==============================] - 26s 17ms/step - loss: 242776.6719 - root_mean_squared_error: 492.7230 - val_loss: 234911.0469 - val_root_mean_squared_error: 484.6754 - lr: 3.7541e-04\n",
      "Epoch 74/200\n",
      "1487/1487 [==============================] - 28s 19ms/step - loss: 242558.5781 - root_mean_squared_error: 492.5016 - val_loss: 234246.8438 - val_root_mean_squared_error: 483.9897 - lr: 3.7541e-04\n",
      "Epoch 75/200\n",
      "1487/1487 [==============================] - 30s 20ms/step - loss: 242307.2656 - root_mean_squared_error: 492.2463 - val_loss: 235913.8125 - val_root_mean_squared_error: 485.7088 - lr: 3.7541e-04\n",
      "Epoch 76/200\n",
      "1487/1487 [==============================] - 36s 24ms/step - loss: 242305.8438 - root_mean_squared_error: 492.2450 - val_loss: 242249.2969 - val_root_mean_squared_error: 492.1877 - lr: 3.6040e-04\n",
      "Epoch 77/200\n",
      "1487/1487 [==============================] - 39s 26ms/step - loss: 242453.7188 - root_mean_squared_error: 492.3953 - val_loss: 240084.5938 - val_root_mean_squared_error: 489.9835 - lr: 3.6040e-04\n",
      "Epoch 78/200\n",
      "1487/1487 [==============================] - 45s 30ms/step - loss: 242624.6406 - root_mean_squared_error: 492.5688 - val_loss: 240869.0312 - val_root_mean_squared_error: 490.7834 - lr: 3.6040e-04\n",
      "Epoch 79/200\n",
      "1487/1487 [==============================] - 41s 28ms/step - loss: 242193.9219 - root_mean_squared_error: 492.1313 - val_loss: 234489.6562 - val_root_mean_squared_error: 484.2406 - lr: 3.4598e-04\n",
      "Epoch 80/200\n",
      "1487/1487 [==============================] - 51s 34ms/step - loss: 242630.7969 - root_mean_squared_error: 492.5750 - val_loss: 234514.5469 - val_root_mean_squared_error: 484.2662 - lr: 3.4598e-04\n",
      "Epoch 81/200\n",
      "1487/1487 [==============================] - 84s 57ms/step - loss: 242330.6250 - root_mean_squared_error: 492.2701 - val_loss: 234393.5469 - val_root_mean_squared_error: 484.1413 - lr: 3.4598e-04\n",
      "Epoch 82/200\n",
      "1487/1487 [==============================] - 31s 21ms/step - loss: 241442.2812 - root_mean_squared_error: 491.3671 - val_loss: 234649.2656 - val_root_mean_squared_error: 484.4055 - lr: 3.3214e-04\n",
      "Epoch 83/200\n",
      "1487/1487 [==============================] - 37s 25ms/step - loss: 242512.6094 - root_mean_squared_error: 492.4548 - val_loss: 236740.8594 - val_root_mean_squared_error: 486.5595 - lr: 3.3214e-04\n",
      "Epoch 84/200\n",
      "1487/1487 [==============================] - 34s 23ms/step - loss: 242328.2500 - root_mean_squared_error: 492.2676 - val_loss: 248668.3594 - val_root_mean_squared_error: 498.6659 - lr: 3.3214e-04\n",
      "Epoch 85/200\n",
      "1487/1487 [==============================] - 35s 23ms/step - loss: 242197.4688 - root_mean_squared_error: 492.1350 - val_loss: 238770.7500 - val_root_mean_squared_error: 488.6409 - lr: 3.1886e-04\n",
      "Epoch 86/200\n",
      "1487/1487 [==============================] - 49s 33ms/step - loss: 241837.9531 - root_mean_squared_error: 491.7695 - val_loss: 234360.1875 - val_root_mean_squared_error: 484.1068 - lr: 3.1886e-04\n",
      "Epoch 87/200\n",
      "1487/1487 [==============================] - 35s 24ms/step - loss: 241553.0156 - root_mean_squared_error: 491.4797 - val_loss: 235199.2031 - val_root_mean_squared_error: 484.9726 - lr: 3.1886e-04\n",
      "Epoch 88/200\n",
      "1487/1487 [==============================] - 49s 33ms/step - loss: 241314.9688 - root_mean_squared_error: 491.2374 - val_loss: 234156.8750 - val_root_mean_squared_error: 483.8966 - lr: 3.0610e-04\n",
      "Epoch 89/200\n",
      "1487/1487 [==============================] - 40s 27ms/step - loss: 241948.4844 - root_mean_squared_error: 491.8817 - val_loss: 234296.2812 - val_root_mean_squared_error: 484.0407 - lr: 3.0610e-04\n",
      "Epoch 90/200\n",
      "1487/1487 [==============================] - 58s 39ms/step - loss: 241242.6562 - root_mean_squared_error: 491.1639 - val_loss: 234409.5781 - val_root_mean_squared_error: 484.1579 - lr: 3.0610e-04\n",
      "Epoch 91/200\n",
      "1487/1487 [==============================] - 49s 33ms/step - loss: 241611.1719 - root_mean_squared_error: 491.5388 - val_loss: 236641.6562 - val_root_mean_squared_error: 486.4574 - lr: 2.9386e-04\n",
      "Epoch 92/200\n",
      "1487/1487 [==============================] - 29s 19ms/step - loss: 241612.2031 - root_mean_squared_error: 491.5397 - val_loss: 234357.4375 - val_root_mean_squared_error: 484.1040 - lr: 2.9386e-04\n",
      "Epoch 93/200\n",
      "1487/1487 [==============================] - 40s 27ms/step - loss: 241348.5469 - root_mean_squared_error: 491.2717 - val_loss: 233961.7656 - val_root_mean_squared_error: 483.6950 - lr: 2.9386e-04\n",
      "Epoch 94/200\n",
      "1487/1487 [==============================] - 37s 25ms/step - loss: 241655.8906 - root_mean_squared_error: 491.5842 - val_loss: 237257.0312 - val_root_mean_squared_error: 487.0895 - lr: 2.8210e-04\n",
      "Epoch 95/200\n",
      "1487/1487 [==============================] - 29s 20ms/step - loss: 241472.1094 - root_mean_squared_error: 491.3972 - val_loss: 237983.4219 - val_root_mean_squared_error: 487.8347 - lr: 2.8210e-04\n",
      "Epoch 96/200\n",
      "1487/1487 [==============================] - 33s 22ms/step - loss: 241046.4062 - root_mean_squared_error: 490.9639 - val_loss: 235501.9062 - val_root_mean_squared_error: 485.2845 - lr: 2.8210e-04\n",
      "Epoch 97/200\n",
      "1487/1487 [==============================] - 31s 21ms/step - loss: 241117.1875 - root_mean_squared_error: 491.0360 - val_loss: 236990.5312 - val_root_mean_squared_error: 486.8158 - lr: 2.7082e-04\n",
      "Epoch 98/200\n",
      "1487/1487 [==============================] - 34s 23ms/step - loss: 240971.4531 - root_mean_squared_error: 490.8876 - val_loss: 236975.3906 - val_root_mean_squared_error: 486.8001 - lr: 2.7082e-04\n",
      "Epoch 99/200\n",
      "1487/1487 [==============================] - 35s 24ms/step - loss: 240849.9531 - root_mean_squared_error: 490.7638 - val_loss: 234778.8594 - val_root_mean_squared_error: 484.5389 - lr: 2.7082e-04\n",
      "Epoch 100/200\n",
      "1487/1487 [==============================] - 39s 26ms/step - loss: 240865.8594 - root_mean_squared_error: 490.7799 - val_loss: 235744.6406 - val_root_mean_squared_error: 485.5345 - lr: 2.5999e-04\n",
      "Epoch 101/200\n",
      "1487/1487 [==============================] - 36s 25ms/step - loss: 241251.0312 - root_mean_squared_error: 491.1722 - val_loss: 239921.3594 - val_root_mean_squared_error: 489.8167 - lr: 2.5999e-04\n",
      "Epoch 102/200\n",
      "1487/1487 [==============================] - 46s 31ms/step - loss: 240952.9688 - root_mean_squared_error: 490.8689 - val_loss: 234275.3281 - val_root_mean_squared_error: 484.0191 - lr: 2.5999e-04\n",
      "Epoch 103/200\n",
      "1487/1487 [==============================] - 50s 33ms/step - loss: 240422.7812 - root_mean_squared_error: 490.3286 - val_loss: 234409.4531 - val_root_mean_squared_error: 484.1578 - lr: 2.4959e-04\n",
      "Epoch 104/200\n",
      "1487/1487 [==============================] - 46s 31ms/step - loss: 240657.4375 - root_mean_squared_error: 490.5676 - val_loss: 234844.6875 - val_root_mean_squared_error: 484.6067 - lr: 2.4959e-04\n",
      "Epoch 105/200\n",
      "1487/1487 [==============================] - 54s 36ms/step - loss: 240667.5938 - root_mean_squared_error: 490.5779 - val_loss: 234684.0781 - val_root_mean_squared_error: 484.4411 - lr: 2.4959e-04\n",
      "Epoch 106/200\n",
      "1487/1487 [==============================] - 44s 29ms/step - loss: 240724.6406 - root_mean_squared_error: 490.6363 - val_loss: 234301.9531 - val_root_mean_squared_error: 484.0467 - lr: 2.3960e-04\n",
      "Epoch 107/200\n",
      "1487/1487 [==============================] - 46s 31ms/step - loss: 240784.9062 - root_mean_squared_error: 490.6976 - val_loss: 241743.5781 - val_root_mean_squared_error: 491.6735 - lr: 2.3960e-04\n",
      "Epoch 108/200\n",
      "1487/1487 [==============================] - 29s 19ms/step - loss: 241209.5156 - root_mean_squared_error: 491.1299 - val_loss: 234612.7812 - val_root_mean_squared_error: 484.3675 - lr: 2.3960e-04\n",
      "Epoch 109/200\n",
      "1487/1487 [==============================] - 27s 18ms/step - loss: 240357.1406 - root_mean_squared_error: 490.2614 - val_loss: 233926.1406 - val_root_mean_squared_error: 483.6581 - lr: 2.3002e-04\n",
      "Epoch 110/200\n",
      "1487/1487 [==============================] - 15s 10ms/step - loss: 240794.2656 - root_mean_squared_error: 490.7069 - val_loss: 235691.2812 - val_root_mean_squared_error: 485.4796 - lr: 2.3002e-04\n",
      "Epoch 111/200\n",
      "1487/1487 [==============================] - 13s 9ms/step - loss: 240619.2344 - root_mean_squared_error: 490.5287 - val_loss: 234578.7188 - val_root_mean_squared_error: 484.3326 - lr: 2.3002e-04\n",
      "Epoch 112/200\n",
      "1487/1487 [==============================] - 14s 9ms/step - loss: 240807.7188 - root_mean_squared_error: 490.7208 - val_loss: 235086.4219 - val_root_mean_squared_error: 484.8564 - lr: 2.2082e-04\n",
      "Epoch 113/200\n",
      "1487/1487 [==============================] - 14s 10ms/step - loss: 240113.0781 - root_mean_squared_error: 490.0125 - val_loss: 234079.4688 - val_root_mean_squared_error: 483.8168 - lr: 2.2082e-04\n",
      "Epoch 114/200\n",
      "1487/1487 [==============================] - 16s 11ms/step - loss: 240384.2031 - root_mean_squared_error: 490.2891 - val_loss: 239514.1406 - val_root_mean_squared_error: 489.4010 - lr: 2.2082e-04\n",
      "Epoch 115/200\n",
      "1487/1487 [==============================] - 16s 11ms/step - loss: 240499.8281 - root_mean_squared_error: 490.4071 - val_loss: 237274.6250 - val_root_mean_squared_error: 487.1076 - lr: 2.1199e-04\n",
      "Epoch 116/200\n",
      "1487/1487 [==============================] - 16s 11ms/step - loss: 240053.5469 - root_mean_squared_error: 489.9518 - val_loss: 233848.8281 - val_root_mean_squared_error: 483.5782 - lr: 2.1199e-04\n",
      "Epoch 117/200\n",
      "1487/1487 [==============================] - 17s 11ms/step - loss: 240445.8281 - root_mean_squared_error: 490.3519 - val_loss: 234257.4688 - val_root_mean_squared_error: 484.0008 - lr: 2.1199e-04\n",
      "Epoch 118/200\n",
      "1487/1487 [==============================] - 15s 10ms/step - loss: 240253.6250 - root_mean_squared_error: 490.1559 - val_loss: 235433.8594 - val_root_mean_squared_error: 485.2144 - lr: 2.0351e-04\n",
      "Epoch 119/200\n",
      "1487/1487 [==============================] - 16s 11ms/step - loss: 240148.2344 - root_mean_squared_error: 490.0483 - val_loss: 235245.7969 - val_root_mean_squared_error: 485.0206 - lr: 2.0351e-04\n",
      "Epoch 120/200\n",
      "1487/1487 [==============================] - 17s 11ms/step - loss: 239934.1406 - root_mean_squared_error: 489.8298 - val_loss: 234369.4062 - val_root_mean_squared_error: 484.1161 - lr: 2.0351e-04\n",
      "Epoch 121/200\n",
      "1487/1487 [==============================] - 15s 10ms/step - loss: 239902.0781 - root_mean_squared_error: 489.7972 - val_loss: 233825.9531 - val_root_mean_squared_error: 483.5547 - lr: 1.9537e-04\n",
      "Epoch 122/200\n",
      "1487/1487 [==============================] - 16s 11ms/step - loss: 240288.1719 - root_mean_squared_error: 490.1909 - val_loss: 235477.2031 - val_root_mean_squared_error: 485.2591 - lr: 1.9537e-04\n",
      "Epoch 123/200\n",
      "1487/1487 [==============================] - 14s 10ms/step - loss: 240144.1094 - root_mean_squared_error: 490.0442 - val_loss: 235038.1719 - val_root_mean_squared_error: 484.8066 - lr: 1.9537e-04\n",
      "Epoch 124/200\n",
      "1487/1487 [==============================] - 17s 11ms/step - loss: 240161.2344 - root_mean_squared_error: 490.0616 - val_loss: 234759.1250 - val_root_mean_squared_error: 484.5186 - lr: 1.8755e-04\n",
      "Epoch 125/200\n",
      "1487/1487 [==============================] - 17s 12ms/step - loss: 240057.7188 - root_mean_squared_error: 489.9560 - val_loss: 238481.0000 - val_root_mean_squared_error: 488.3443 - lr: 1.8755e-04\n",
      "Epoch 126/200\n",
      "1487/1487 [==============================] - 16s 11ms/step - loss: 239968.3281 - root_mean_squared_error: 489.8647 - val_loss: 234099.2031 - val_root_mean_squared_error: 483.8371 - lr: 1.8755e-04\n",
      "Epoch 127/200\n",
      "1487/1487 [==============================] - 15s 10ms/step - loss: 239938.0000 - root_mean_squared_error: 489.8338 - val_loss: 234874.5781 - val_root_mean_squared_error: 484.6377 - lr: 1.8005e-04\n",
      "Epoch 128/200\n",
      "1487/1487 [==============================] - 14s 9ms/step - loss: 240143.8906 - root_mean_squared_error: 490.0439 - val_loss: 234090.0000 - val_root_mean_squared_error: 483.8276 - lr: 1.8005e-04\n",
      "Epoch 129/200\n",
      "1487/1487 [==============================] - 13s 9ms/step - loss: 240085.4844 - root_mean_squared_error: 489.9843 - val_loss: 234990.0312 - val_root_mean_squared_error: 484.7569 - lr: 1.8005e-04\n",
      "Epoch 130/200\n",
      "1487/1487 [==============================] - 13s 9ms/step - loss: 240125.7031 - root_mean_squared_error: 490.0254 - val_loss: 234576.3594 - val_root_mean_squared_error: 484.3299 - lr: 1.7285e-04\n",
      "Epoch 131/200\n",
      "1487/1487 [==============================] - 10s 7ms/step - loss: 239745.0000 - root_mean_squared_error: 489.6367 - val_loss: 233969.2656 - val_root_mean_squared_error: 483.7029 - lr: 1.7285e-04\n",
      "Epoch 132/200\n",
      "1487/1487 [==============================] - 10s 7ms/step - loss: 239636.7969 - root_mean_squared_error: 489.5261 - val_loss: 237316.0625 - val_root_mean_squared_error: 487.1501 - lr: 1.7285e-04\n",
      "Epoch 133/200\n",
      "1487/1487 [==============================] - 10s 7ms/step - loss: 239662.7031 - root_mean_squared_error: 489.5528 - val_loss: 234611.3750 - val_root_mean_squared_error: 484.3661 - lr: 1.6593e-04\n",
      "Epoch 134/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239766.6719 - root_mean_squared_error: 489.6588 - val_loss: 235950.1094 - val_root_mean_squared_error: 485.7460 - lr: 1.6593e-04\n",
      "Epoch 135/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 240148.0938 - root_mean_squared_error: 490.0482 - val_loss: 233848.7031 - val_root_mean_squared_error: 483.5782 - lr: 1.6593e-04\n",
      "Epoch 136/200\n",
      "1487/1487 [==============================] - 10s 6ms/step - loss: 239394.8125 - root_mean_squared_error: 489.2789 - val_loss: 233915.6250 - val_root_mean_squared_error: 483.6473 - lr: 1.5930e-04\n",
      "Epoch 137/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239762.5625 - root_mean_squared_error: 489.6546 - val_loss: 234130.9844 - val_root_mean_squared_error: 483.8699 - lr: 1.5930e-04\n",
      "Epoch 138/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239783.6719 - root_mean_squared_error: 489.6764 - val_loss: 236043.4688 - val_root_mean_squared_error: 485.8422 - lr: 1.5930e-04\n",
      "Epoch 139/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239650.1094 - root_mean_squared_error: 489.5398 - val_loss: 234404.9219 - val_root_mean_squared_error: 484.1530 - lr: 1.5292e-04\n",
      "Epoch 140/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239659.1562 - root_mean_squared_error: 489.5491 - val_loss: 238685.3125 - val_root_mean_squared_error: 488.5533 - lr: 1.5292e-04\n",
      "Epoch 141/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239486.4844 - root_mean_squared_error: 489.3727 - val_loss: 234384.7031 - val_root_mean_squared_error: 484.1320 - lr: 1.5292e-04\n",
      "Epoch 142/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239591.4062 - root_mean_squared_error: 489.4799 - val_loss: 233566.4062 - val_root_mean_squared_error: 483.2861 - lr: 1.4681e-04\n",
      "Epoch 143/200\n",
      "1487/1487 [==============================] - 10s 7ms/step - loss: 239457.6406 - root_mean_squared_error: 489.3431 - val_loss: 233804.5625 - val_root_mean_squared_error: 483.5324 - lr: 1.4681e-04\n",
      "Epoch 144/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239457.7500 - root_mean_squared_error: 489.3432 - val_loss: 233856.2656 - val_root_mean_squared_error: 483.5859 - lr: 1.4681e-04\n",
      "Epoch 145/200\n",
      "1487/1487 [==============================] - 10s 6ms/step - loss: 239440.1719 - root_mean_squared_error: 489.3254 - val_loss: 234298.5625 - val_root_mean_squared_error: 484.0431 - lr: 1.4094e-04\n",
      "Epoch 146/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239374.9375 - root_mean_squared_error: 489.2586 - val_loss: 233799.5312 - val_root_mean_squared_error: 483.5273 - lr: 1.4094e-04\n",
      "Epoch 147/200\n",
      "1487/1487 [==============================] - 10s 6ms/step - loss: 239407.2188 - root_mean_squared_error: 489.2916 - val_loss: 233657.8281 - val_root_mean_squared_error: 483.3807 - lr: 1.4094e-04\n",
      "Epoch 148/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239138.9688 - root_mean_squared_error: 489.0173 - val_loss: 233738.2500 - val_root_mean_squared_error: 483.4640 - lr: 1.3530e-04\n",
      "Epoch 149/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239312.4844 - root_mean_squared_error: 489.1948 - val_loss: 234073.6094 - val_root_mean_squared_error: 483.8107 - lr: 1.3530e-04\n",
      "Epoch 150/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239241.2656 - root_mean_squared_error: 489.1222 - val_loss: 233546.6562 - val_root_mean_squared_error: 483.2657 - lr: 1.3530e-04\n",
      "Epoch 151/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239290.0781 - root_mean_squared_error: 489.1718 - val_loss: 233615.4688 - val_root_mean_squared_error: 483.3368 - lr: 1.2989e-04\n",
      "Epoch 152/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239424.2500 - root_mean_squared_error: 489.3090 - val_loss: 235725.1250 - val_root_mean_squared_error: 485.5145 - lr: 1.2989e-04\n",
      "Epoch 153/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239105.8594 - root_mean_squared_error: 488.9836 - val_loss: 236852.8125 - val_root_mean_squared_error: 486.6742 - lr: 1.2989e-04\n",
      "Epoch 154/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239145.0781 - root_mean_squared_error: 489.0236 - val_loss: 235591.1719 - val_root_mean_squared_error: 485.3765 - lr: 1.2469e-04\n",
      "Epoch 155/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239235.5312 - root_mean_squared_error: 489.1161 - val_loss: 235928.1875 - val_root_mean_squared_error: 485.7235 - lr: 1.2469e-04\n",
      "Epoch 156/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239316.7031 - root_mean_squared_error: 489.1990 - val_loss: 233776.8438 - val_root_mean_squared_error: 483.5040 - lr: 1.2469e-04\n",
      "Epoch 157/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239065.1406 - root_mean_squared_error: 488.9422 - val_loss: 233954.1562 - val_root_mean_squared_error: 483.6871 - lr: 1.1970e-04\n",
      "Epoch 158/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239309.9062 - root_mean_squared_error: 489.1922 - val_loss: 235600.2188 - val_root_mean_squared_error: 485.3857 - lr: 1.1970e-04\n",
      "Epoch 159/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239161.1562 - root_mean_squared_error: 489.0401 - val_loss: 235232.3281 - val_root_mean_squared_error: 485.0066 - lr: 1.1970e-04\n",
      "Epoch 160/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239244.3438 - root_mean_squared_error: 489.1252 - val_loss: 233728.9219 - val_root_mean_squared_error: 483.4543 - lr: 1.1491e-04\n",
      "Epoch 161/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239060.0156 - root_mean_squared_error: 488.9367 - val_loss: 234491.0469 - val_root_mean_squared_error: 484.2418 - lr: 1.1491e-04\n",
      "Epoch 162/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239028.6406 - root_mean_squared_error: 488.9048 - val_loss: 235520.1094 - val_root_mean_squared_error: 485.3031 - lr: 1.1491e-04\n",
      "Epoch 163/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239096.0469 - root_mean_squared_error: 488.9735 - val_loss: 234093.0000 - val_root_mean_squared_error: 483.8306 - lr: 1.1032e-04\n",
      "Epoch 164/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239073.5781 - root_mean_squared_error: 488.9508 - val_loss: 234729.8125 - val_root_mean_squared_error: 484.4885 - lr: 1.1032e-04\n",
      "Epoch 165/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239117.7031 - root_mean_squared_error: 488.9955 - val_loss: 234338.6875 - val_root_mean_squared_error: 484.0844 - lr: 1.1032e-04\n",
      "Epoch 166/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239125.4688 - root_mean_squared_error: 489.0036 - val_loss: 233748.5938 - val_root_mean_squared_error: 483.4746 - lr: 1.0591e-04\n",
      "Epoch 167/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238818.0312 - root_mean_squared_error: 488.6892 - val_loss: 234404.6406 - val_root_mean_squared_error: 484.1526 - lr: 1.0591e-04\n",
      "Epoch 168/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238888.8906 - root_mean_squared_error: 488.7617 - val_loss: 234059.3125 - val_root_mean_squared_error: 483.7958 - lr: 1.0591e-04\n",
      "Epoch 169/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238979.6562 - root_mean_squared_error: 488.8546 - val_loss: 233899.7031 - val_root_mean_squared_error: 483.6307 - lr: 1.0167e-04\n",
      "Epoch 170/200\n",
      "1487/1487 [==============================] - 8s 6ms/step - loss: 238983.1094 - root_mean_squared_error: 488.8582 - val_loss: 233726.0469 - val_root_mean_squared_error: 483.4513 - lr: 1.0167e-04\n",
      "Epoch 171/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239069.6562 - root_mean_squared_error: 488.9468 - val_loss: 234528.6719 - val_root_mean_squared_error: 484.2806 - lr: 1.0167e-04\n",
      "Epoch 172/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238938.4062 - root_mean_squared_error: 488.8123 - val_loss: 234249.7969 - val_root_mean_squared_error: 483.9926 - lr: 9.7602e-05\n",
      "Epoch 173/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238926.7344 - root_mean_squared_error: 488.8004 - val_loss: 233861.3750 - val_root_mean_squared_error: 483.5912 - lr: 9.7602e-05\n",
      "Epoch 174/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238819.3750 - root_mean_squared_error: 488.6905 - val_loss: 234017.0469 - val_root_mean_squared_error: 483.7522 - lr: 9.7602e-05\n",
      "Epoch 175/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238937.2500 - root_mean_squared_error: 488.8113 - val_loss: 235004.4531 - val_root_mean_squared_error: 484.7716 - lr: 9.3698e-05\n",
      "Epoch 176/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238998.7344 - root_mean_squared_error: 488.8740 - val_loss: 233470.6719 - val_root_mean_squared_error: 483.1871 - lr: 9.3698e-05\n",
      "Epoch 177/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238790.4219 - root_mean_squared_error: 488.6607 - val_loss: 235995.4375 - val_root_mean_squared_error: 485.7927 - lr: 9.3698e-05\n",
      "Epoch 178/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238777.1406 - root_mean_squared_error: 488.6474 - val_loss: 233896.1562 - val_root_mean_squared_error: 483.6273 - lr: 8.9950e-05\n",
      "Epoch 179/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238729.5469 - root_mean_squared_error: 488.5987 - val_loss: 235190.5156 - val_root_mean_squared_error: 484.9635 - lr: 8.9950e-05\n",
      "Epoch 180/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 239118.8125 - root_mean_squared_error: 488.9967 - val_loss: 233893.7656 - val_root_mean_squared_error: 483.6248 - lr: 8.9950e-05\n",
      "Epoch 181/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238723.0781 - root_mean_squared_error: 488.5921 - val_loss: 233644.6562 - val_root_mean_squared_error: 483.3671 - lr: 8.6352e-05\n",
      "Epoch 182/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238615.9375 - root_mean_squared_error: 488.4825 - val_loss: 234023.6406 - val_root_mean_squared_error: 483.7590 - lr: 8.6352e-05\n",
      "Epoch 183/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238928.1406 - root_mean_squared_error: 488.8018 - val_loss: 234423.8906 - val_root_mean_squared_error: 484.1724 - lr: 8.6352e-05\n",
      "Epoch 184/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238668.0781 - root_mean_squared_error: 488.5358 - val_loss: 235306.6562 - val_root_mean_squared_error: 485.0833 - lr: 8.2898e-05\n",
      "Epoch 185/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238744.5000 - root_mean_squared_error: 488.6139 - val_loss: 233611.4219 - val_root_mean_squared_error: 483.3328 - lr: 8.2898e-05\n",
      "Epoch 186/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238673.1406 - root_mean_squared_error: 488.5410 - val_loss: 233894.7188 - val_root_mean_squared_error: 483.6256 - lr: 8.2898e-05\n",
      "Epoch 187/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238651.0781 - root_mean_squared_error: 488.5184 - val_loss: 234191.9219 - val_root_mean_squared_error: 483.9329 - lr: 7.9582e-05\n",
      "Epoch 188/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238580.6562 - root_mean_squared_error: 488.4462 - val_loss: 233995.3906 - val_root_mean_squared_error: 483.7297 - lr: 7.9582e-05\n",
      "Epoch 189/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238587.5000 - root_mean_squared_error: 488.4532 - val_loss: 234086.1562 - val_root_mean_squared_error: 483.8236 - lr: 7.9582e-05\n",
      "Epoch 190/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238600.0000 - root_mean_squared_error: 488.4661 - val_loss: 233577.6406 - val_root_mean_squared_error: 483.2977 - lr: 7.6399e-05\n",
      "Epoch 191/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238624.9688 - root_mean_squared_error: 488.4917 - val_loss: 234563.0312 - val_root_mean_squared_error: 484.3160 - lr: 7.6399e-05\n",
      "Epoch 192/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238643.6250 - root_mean_squared_error: 488.5106 - val_loss: 233728.4688 - val_root_mean_squared_error: 483.4538 - lr: 7.6399e-05\n",
      "Epoch 193/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238627.0781 - root_mean_squared_error: 488.4937 - val_loss: 233606.8594 - val_root_mean_squared_error: 483.3282 - lr: 7.3343e-05\n",
      "Epoch 194/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238490.2656 - root_mean_squared_error: 488.3538 - val_loss: 234915.4688 - val_root_mean_squared_error: 484.6800 - lr: 7.3343e-05\n",
      "Epoch 195/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238549.0469 - root_mean_squared_error: 488.4138 - val_loss: 234554.9375 - val_root_mean_squared_error: 484.3078 - lr: 7.3343e-05\n",
      "Epoch 196/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238536.6875 - root_mean_squared_error: 488.4012 - val_loss: 234347.1719 - val_root_mean_squared_error: 484.0933 - lr: 7.0409e-05\n",
      "Epoch 197/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238626.3438 - root_mean_squared_error: 488.4931 - val_loss: 235068.9844 - val_root_mean_squared_error: 484.8383 - lr: 7.0409e-05\n",
      "Epoch 198/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238672.7969 - root_mean_squared_error: 488.5405 - val_loss: 234281.5156 - val_root_mean_squared_error: 484.0255 - lr: 7.0409e-05\n",
      "Epoch 199/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238560.1094 - root_mean_squared_error: 488.4253 - val_loss: 235002.3438 - val_root_mean_squared_error: 484.7695 - lr: 6.7593e-05\n",
      "Epoch 200/200\n",
      "1487/1487 [==============================] - 9s 6ms/step - loss: 238410.0156 - root_mean_squared_error: 488.2715 - val_loss: 233887.0469 - val_root_mean_squared_error: 483.6177 - lr: 6.7593e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_factor = 0.96\n",
    "    decay_steps = 3\n",
    "    lr = initial_learning_rate * (decay_factor ** (epoch // decay_steps))\n",
    "    return lr\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(46,)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(46, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[lr_callback])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T07:04:58.754629600Z",
     "start_time": "2023-11-07T06:14:04.021831900Z"
    }
   },
   "id": "2eb4f8c90ccb3ee6"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRIRAM\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"nn_regression_model_5_final.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T07:04:59.316277100Z",
     "start_time": "2023-11-07T07:04:59.143896700Z"
    }
   },
   "id": "ff0e9b9c2a67cc01"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 1s 1ms/step\n",
      "RMSE on Validation Set: 483.6177\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation set\n",
    "predictions = model.predict(X_val)\n",
    "a,b = predictions.shape\n",
    "predictions = predictions.reshape(a,)\n",
    "# Calculate RMSE on the validation set\n",
    "rmse_val = np.sqrt(np.mean((predictions - y_val) ** 2))\n",
    "print(f'RMSE on Validation Set: {rmse_val:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T07:06:34.045163800Z",
     "start_time": "2023-11-07T07:06:32.696641300Z"
    }
   },
   "id": "4c9627a95230ee85"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Models performance comparison:\n",
    "Models and RMSE on val set:\n",
    "Model-1: 495.3260\n",
    "Model-2: 492.2489\n",
    "Model-3: 493.9776\n",
    "Model-4: 491.8362\n",
    "Model-5: 483.6177\n",
    "\n",
    "Neural networks are not able to go below a loss of 490 RMSE. The volume of data available is not enough for the network to learn effectively and hence the performance is not as good as traditional regressors and tree-based regressors. </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9433c646b712aaa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model-5 seems to be the best of the bunch. Hence we predict on the test dataset using the saved model-5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bb2aa8af4fc14d6"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "   rent_approval_date  flat_type  floor_area_sqm  lease_commence_date  \\\n0            0.801317       0.75        0.480663             0.339623   \n1            0.667398       0.50        0.364641             0.622642   \n2            1.000000       0.50        0.314917             0.264151   \n3            0.232711       0.25        0.220994             0.377358   \n4            0.465423       0.75        0.480663             0.320755   \n\n   latitude   longitude  distance_to_nearest_existing_mrt  \\\n0  1.358411  103.891722                          0.321608   \n1  1.446343  103.820817                          0.111405   \n2  1.305719  103.762168                          0.435355   \n3  1.344832  103.730778                          0.133972   \n4  1.345437  103.735241                          0.169311   \n\n   distance_to_nearest_planned_mrt  distance_to_nearest_school  \\\n0                         0.092001                    0.052465   \n1                         0.933200                    0.049352   \n2                         0.074979                    0.489875   \n3                         0.109898                    0.506897   \n4                         0.079866                    0.329833   \n\n   distance_to_nearest_mall  ...  town_pasir ris  town_punggol  \\\n0                  0.317300  ...               0             0   \n1                  0.109394  ...               0             0   \n2                  0.213565  ...               0             0   \n3                  0.685062  ...               0             0   \n4                  0.627168  ...               0             0   \n\n   town_queenstown  town_sembawang  town_sengkang  town_serangoon  \\\n0                0               0              0               0   \n1                0               1              0               0   \n2                0               0              0               0   \n3                0               0              0               0   \n4                0               0              0               0   \n\n   town_tampines  town_toa payoh  town_woodlands  town_yishun  \n0              0               0               0            0  \n1              0               0               0            0  \n2              0               0               0            0  \n3              0               0               0            0  \n4              0               0               0            0  \n\n[5 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rent_approval_date</th>\n      <th>flat_type</th>\n      <th>floor_area_sqm</th>\n      <th>lease_commence_date</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>distance_to_nearest_existing_mrt</th>\n      <th>distance_to_nearest_planned_mrt</th>\n      <th>distance_to_nearest_school</th>\n      <th>distance_to_nearest_mall</th>\n      <th>...</th>\n      <th>town_pasir ris</th>\n      <th>town_punggol</th>\n      <th>town_queenstown</th>\n      <th>town_sembawang</th>\n      <th>town_sengkang</th>\n      <th>town_serangoon</th>\n      <th>town_tampines</th>\n      <th>town_toa payoh</th>\n      <th>town_woodlands</th>\n      <th>town_yishun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.801317</td>\n      <td>0.75</td>\n      <td>0.480663</td>\n      <td>0.339623</td>\n      <td>1.358411</td>\n      <td>103.891722</td>\n      <td>0.321608</td>\n      <td>0.092001</td>\n      <td>0.052465</td>\n      <td>0.317300</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.667398</td>\n      <td>0.50</td>\n      <td>0.364641</td>\n      <td>0.622642</td>\n      <td>1.446343</td>\n      <td>103.820817</td>\n      <td>0.111405</td>\n      <td>0.933200</td>\n      <td>0.049352</td>\n      <td>0.109394</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>0.50</td>\n      <td>0.314917</td>\n      <td>0.264151</td>\n      <td>1.305719</td>\n      <td>103.762168</td>\n      <td>0.435355</td>\n      <td>0.074979</td>\n      <td>0.489875</td>\n      <td>0.213565</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.232711</td>\n      <td>0.25</td>\n      <td>0.220994</td>\n      <td>0.377358</td>\n      <td>1.344832</td>\n      <td>103.730778</td>\n      <td>0.133972</td>\n      <td>0.109898</td>\n      <td>0.506897</td>\n      <td>0.685062</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.465423</td>\n      <td>0.75</td>\n      <td>0.480663</td>\n      <td>0.320755</td>\n      <td>1.345437</td>\n      <td>103.735241</td>\n      <td>0.169311</td>\n      <td>0.079866</td>\n      <td>0.329833</td>\n      <td>0.627168</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 46 columns</p>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test =pd.read_csv('../datasets/final/test_clean.csv')\n",
    "X_test.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T05:21:00.588321400Z",
     "start_time": "2023-11-06T05:21:00.442234800Z"
    }
   },
   "id": "a43b9a946c37d9af"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# for final model-5\n",
    "\n",
    "X_test =pd.read_csv('../../datasets/final/test_clean.csv')\n",
    "X_test.head()\n",
    "\n",
    "# Make predictions on the Test\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"nn_regression_model_5_final.h5\")\n",
    "predictions = model.predict(X_test)\n",
    "a,b = predictions.shape\n",
    "predictions_test = predictions.reshape(a,)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T07:08:02.284276800Z",
     "start_time": "2023-11-07T07:07:59.518942300Z"
    }
   },
   "id": "f028faf5387c5023"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "          Id    Predicted\n0          0  3074.443604\n1          1  2702.907227\n2          2  3535.118896\n3          3  1915.916992\n4          4  2759.219971\n...      ...          ...\n29995  29995  2898.543457\n29996  29996  3007.866211\n29997  29997  2702.607910\n29998  29998  3363.416504\n29999  29999  3626.233154\n\n[30000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3074.443604</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2702.907227</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3535.118896</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1915.916992</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2759.219971</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>29995</td>\n      <td>2898.543457</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>29996</td>\n      <td>3007.866211</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>29997</td>\n      <td>2702.607910</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>29998</td>\n      <td>3363.416504</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>29999</td>\n      <td>3626.233154</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.data_utils import save_test_predictions_in_kaggle_format\n",
    "\n",
    "save_test_predictions_in_kaggle_format(predictions_test, 'neural_network_best_model', True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T07:08:20.674083700Z",
     "start_time": "2023-11-07T07:08:20.474398500Z"
    }
   },
   "id": "f61eb4be10b8046f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3b8936ad855d7661"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
